<!--- # MachineLearning --->
Included is a collection of my machine learning projects as well as my homework assignments for the online Machine Learning course offered by Stanford through coursera programmed in Matlab.  

# Table of Contents 
1. [MachineLearning](#MachineLearning)
2. [Bank](#Bank)
3. [machine-learning-ex](#machine-learning-ex)

## MachineLearning
Python modules that implement various machine learning models such as linear regression, logisitic regression, and neural network.  Adadelta.py is a modified gradient descent type algorithm (arXiv:1212.5701). The machine learning modules also contain examples that reproduce results from the Matlab coursera homework assignments. The relavent data files are included. Supervised.py combines the three mentioned modules.

## Bank
Jupyter notebook of a classification problem that loads data from http://archive.ics.uci.edu/ml/datasets/Bank+Marketing and follows https://towardsdatascience.com/data-handling-using-pandas-machine-learning-in-real-life-be76a697418c to predict if the client will subscribe (yes/no) a term deposit. The code uses my implemented logistic regression and neural network codes as well as sklearn. The relevant csv files are also included. 

## machine-learning-ex
Matlab homework assignments for the online certification course through Standford. Each homework assignment is labeled as ex(1-8). Various topics included are
- Linear Regression
- Logistic Regression
- Neural Networks
- Feature Scaling
- Gradient Descent
- K-means clustering
- Principle Componant Analysis (PCA)
  
<!---
# Table of Contents
1. [Linear Regression ex1](#Linear-Regression-ex1)
2. [Logistic Regression ex2](#Logistic-Regression-ex2)

## Linear Regression ex1

Objectives

<pre>
 
                                   Part Name |     Score | Feedback
                                   --------- |     ----- | --------
                            Warm-up Exercise |  10 /  10 | Nice work!
           Computing Cost (for One Variable) |  40 /  40 | Nice work!
         Gradient Descent (for One Variable) |  50 /  50 | Nice work!
                       Feature Normalization |   0 /   0 | Nice work!
     Computing Cost (for Multiple Variables) |   0 /   0 | Nice work!
   Gradient Descent (for Multiple Variables) |   0 /   0 | Nice work!
                            Normal Equations |   0 /   0 | Nice work!
                                   --------------------------------
                                             | 100 / 100 | 

</pre>

Sample Plots

<p float="center">
 <img src="https://github.com/vagiedd/MachineLearning-Matlab/blob/main/ex1/A39B530C-8953-450D-9631-6401FF86647B.png" width="50%" height="50%">
 <img src="https://github.com/vagiedd/MachineLearning-Matlab/blob/main/ex1/BD674829-7A17-4EFF-9A70-D3FEA629ABC7.png" width="50%" height="50%">
 
</p>

<p align="center">
 <img src="https://github.com/vagiedd/MachineLearning-Matlab/blob/main/ex1/44F27504-4BD8-4F1D-9BE7-F3B72BEB24C7.png" width="50%" height="50%">
</p>

## Logistic Regression ex2

-->
